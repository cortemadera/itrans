{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from numpy import array\n",
    "\n",
    "def read_data(file):\n",
    "    pairs = []\n",
    "    f = open(file, mode='r', encoding ='utf8')\n",
    "    for x in f:\n",
    "        sample = json.loads(x)\n",
    "        pair = [sample['source'], sample['target']]\n",
    "        pairs.append(pair)\n",
    "    return array(pairs)\n",
    "\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "    prediction = model.predict(source, verbose=0)[0]\n",
    "    integers = [argmax(vector) for vector in prediction]\n",
    "    target = list()\n",
    "    for i in integers:\n",
    "        word = word_for_id(i, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)\n",
    "\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x104202598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Tom's tired:[[112 188   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]:汤姆 很 了 。\n",
      "They hugged:[[  46 1097    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]]:他 点 。\n",
      "hug me:[[1041   10    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]]:请 ！ ！ 。\n",
      "i:[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]:我\n",
      "Unbelievable!:[[1666    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]]:汤姆 。\n",
      "i ran:[[  1 314   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]:我 。 。\n",
      "Got it:[[69  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0]]:请 点 ！ 。\n",
      "hug me:[[1041   10    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]]:请 ！ ！ 。\n",
      "i:[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]:我\n",
      "Wait!:[[157   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]:我 ！ ！\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from numpy import argmax\n",
    "\n",
    "model = load_model('mtrans.h5')\n",
    "myData = read_data('tiny.json')[:10]\n",
    "\n",
    "from ipynb.fs.full.model import encode_sequences\n",
    "from ipynb.fs.full.model import src_tok\n",
    "from ipynb.fs.full.model import src_length\n",
    "from ipynb.fs.full.model import tgt_tok\n",
    "\n",
    "myTest = encode_sequences(src_tok, src_length, myData[:,0])\n",
    "\n",
    "for count, source in enumerate(myTest):\n",
    "    source = source.reshape((1, source.shape[0]))\n",
    "    translation = predict_sequence(model, tgt_tok, source)\n",
    "    print(myData[:,0][count], source, translation, sep=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
